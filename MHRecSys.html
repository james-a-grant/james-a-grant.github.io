<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="James A. Grant" />


<title>Investigating a small-scale Recommender System</title>

<script src="MHRecSys_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="MHRecSys_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="MHRecSys_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="MHRecSys_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="MHRecSys_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="MHRecSys_files/navigation-1.1/tabsets.js"></script>
<script src="MHRecSys_files/navigation-1.1/codefolding.js"></script>
<link href="MHRecSys_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="MHRecSys_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Investigating a small-scale Recommender System</h1>
<h4 class="author">James A. Grant</h4>

</div>


<div id="set-up" class="section level2">
<h2>1. Set-up</h2>
<p>We want to test how well a recommender system can detect some structure in the ratings of a population - i.e. how it can pick up similarities and patterns in the preferences of users. To assess this we will build a simple dataset that we know has some such structure in it, and therefore something that we may expect a reasonable method to be able to predict. We first set a number of items, <span class="math inline">\(I\)</span>, and a number of users, <span class="math inline">\(U\)</span>, and decide how many items each user will have rated. The more items have been rated, the easier the unobserved ratings should be to infer. In this particular example we suppose that each item is a story that can be recommended to a user, although the techniques we are using can be used across many applications.</p>
<pre class="r"><code>n.items    &lt;- 40             # Number of items
n.users    &lt;- 100            # Number of users
n.initial  &lt;- 10             # Number of initial ratings (less than n.items)</code></pre>
<p>Each user <span class="math inline">\(u\)</span> assigns a rating <span class="math inline">\(R_{ui}\)</span> to each item <span class="math inline">\(i\)</span>. The higher the rating, the more the user “likes” the item. We assume that ratings are generated from a linear model based on attributes of the users, and of the items.</p>
<p>In particular, we assume that a user <span class="math inline">\(u\)</span> has two relevant binary attributes <span class="math inline">\(\beta_{u,1},\beta_{u,2}\)</span> which each are coded as 1 or -1. These could be things like whether they are over/under 25 years of age or their sex.</p>
<p>Each item has two relevant attributes <span class="math inline">\(\gamma_{i,1}, \gamma_{i,2}\)</span> which take continuous values. These could be measures of things like how well a story captures the experiences of a particular sex or how relevant it is to younger people versus older people.</p>
<p>We then assume that the ratings are normally distributed: <span class="math display">\[R_{ui} \sim N(\beta_{u,1}\gamma_{i,1}+\beta_{u,2}\gamma_{i,2},\sigma^2)\]</span> for some variance parameter <span class="math inline">\(\sigma^2\)</span>. We finally apply a transformation to these random values to get ratings on the [0,1] scale.</p>
<p>The code below generates a set of ratings, based on equal representation of users across four groups (based on their <span class="math inline">\(\beta\)</span> covariates).</p>
<pre class="r"><code># Create users from four populations (AA, AB, BA, BB)
user.covariates &lt;- matrix(c(rep(1,n.users/2),rep(-1,n.users/2),
                            rep(1,n.users/4),rep(-1,n.users/4),
                            rep(1,n.users/4),rep(-1,n.users/4)),
                            ncol=2,byrow=F)
# Create items with two numeric characteristics
item.covariates &lt;- matrix(c(rnorm(2*n.items,0,1)),ncol=2,byrow=F)

sig        &lt;- 0.1              # Ratings variance
# Generate Gaussian ratings
true.ratings &lt;- matrix(nrow=n.users,ncol=n.items)
for (i in 1:n.users){
  for (j in 1:n.items){
    true.ratings[i,j] &lt;- rnorm(1,t(item.covariates[j,])%*%user.covariates[i,],
                               sig)
  }
}
# Transform to [0,1] scale
true.ratings &lt;- apply(true.ratings,2,sigmoid)</code></pre>
<p>We plot these ratings below in a heatmap - here lighter colours represent higher ratings. Items are on the horizontal axis and users are on the vertical axis. The similarities within the groups, and the differences across them are quite clear. For the rest of this example, these ratings will be treated as ground truth, and we assume that if a user is recommended an item, they faithfully report their true rating of the item. Our objective is to recommend items to users that have high ratings.</p>
<pre class="r"><code>ggplot(data = yy, aes(y=rowname, x=variable, fill=value)) + 
  geom_tile() +labs(x=&quot;Item&quot;,y=&quot;User&quot;,title=&quot;True Ratings&quot;) </code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>We want to design a system that can suggest stories to people based on a small number of ratings they provide. We suppose that each user has been asked to provide their rating for 10 items (chosen at random) giving us the following data - a subset of the full dataset, which recommender systems will not have access to.</p>
<pre class="r"><code># Subsample to get Observed data
obs.ind  &lt;-  matrix(0L,nrow=n.users,ncol=n.initial)
for (i in 1:n.users){
  obs.ind[i,] &lt;- sample(n.items,n.initial)
}
obs.ratings &lt;- matrix(0L,nrow=n.users,ncol=n.items)
for(i in 1:n.users){
  for (k in 1:n.initial){
    obs.ratings[i,obs.ind[i,k]]&lt;-true.ratings[i,obs.ind[i,k]]
  }
}
# Put NAs in for missing data and tidy for plotting
obs.ratings2 &lt;- matrix(nrow=n.users,ncol=n.items)
for(i in 1:n.users){
  for (k in 1:n.initial){
    obs.ratings2[i,obs.ind[i,k]]&lt;-true.ratings[i,obs.ind[i,k]]
  }
}
yy     &lt;- as.data.frame(obs.ratings2)
names(yy) &lt;- c(1:n.items)
yy$rowname &lt;- c(1:n.users)
yy &lt;- melt(yy,id=&quot;rowname&quot;)

# Visualise observed data
ggplot(data = yy, aes(y=rowname, x=variable, fill=value)) + 
  geom_tile() +scale_fill_continuous(na.value=&quot;white&quot;) +
  labs(x=&quot;Item&quot;,y=&quot;User&quot;,title=&quot;Observed Ratings&quot;) </code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="recommender-model-predictions" class="section level2">
<h2>2. Recommender Model + Predictions</h2>
<p>We process our data in to a suitable format and then run it through a standard “matrix factorization” algorithm. This approach considers the similarities between the responses of different users and the responses for different items and makes predictions of the unobserved ratings. It does not receive any information on the covariates of users and items - only the rating data.</p>
<pre class="r"><code>#Convert to form required for recommender
## Should be able to do this more efficiently with Matrix package.
# Observed Data
obs.list &lt;- numeric(3)
for(i in 1:n.users){
  for(j in 1:n.items){
    if(obs.ratings[i,j]!=0){
      obs.list &lt;- rbind(obs.list,c(i,j,obs.ratings[i,j]))
    }
  }
}
obs.list &lt;- obs.list[-1,]
obs.list &lt;- data_memory(obs.list[,1],obs.list[,2],obs.list[,3])

#Unobserved Data
unobs.list &lt;- numeric(3)
for(i in 1:n.users){
  for(j in 1:n.items){
    if(obs.ratings[i,j]==0){
      unobs.list &lt;- rbind(unobs.list,c(i,j,0))
    }
  }
}
unobs.list &lt;- unobs.list[-1,]
unobs.list2 &lt;- data_memory(unobs.list[,1],unobs.list[,2],unobs.list[,3])

# Fit the matrix factorization model
model &lt;- Reco()                              # Initialise the model
model$train(obs.list)                        # Train the model on observed data
pred_file    &lt;- tempfile()                   # Make predictions
predictions  &lt;- model$predict(unobs.list2, out_memory())
unobs.list[,3] &lt;- predictions                # Associate with unobserved pairs

# Generate matrix of predicted values
pred.ratings &lt;- obs.ratings
for(l in 1:nrow(unobs.list)){
  pred.ratings[unobs.list[l,1],unobs.list[l,2]] &lt;- unobs.list[l,3]
}</code></pre>
<p>The predictions of the matrix factorization model are shown below, alongside the true ratings matrix. We can see that the model’s predictions are quite inaccurate. It seems not to have enough data to make strong predictions about most unknown values and chooses values around the mean ratings for most user and item pairs. Later, we will explore how this varies with changing amounts of initial data.</p>
<pre class="r"><code>#Visualise Predictions
ggplot(data = xx, aes(y=rowname, x=variable, fill=value)) + 
  geom_tile() +labs(x=&quot;Item&quot;,y=&quot;User&quot;,title=&quot;Predicted Ratings&quot;) </code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = yy, aes(y=rowname, x=variable, fill=value)) + 
  geom_tile() +labs(x=&quot;Item&quot;,y=&quot;User&quot;,title=&quot;True Ratings&quot;) </code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
</div>
<div id="evaluation" class="section level2">
<h2>3. Evaluation</h2>
<p>Beyond eyeballing the data, it is interesting to numerically evaluate the recommender system. One option is to measure the error in the estimates of the rating parameters, however we are ultimately interested in the quality of decisions (recommendations) made by the algorithm, so more interesting metrics are based on the accuracy of the decisions.</p>
<p>Below, we consider recommending one item to each user. We choose the item with the highest predicted rating, amongst those that they have not previously rated for each user. We will compare this to approaches which choose an item to recommend randomly and those which recommend the most popular items, without considering the varying preferences across user groups.</p>
<p>We consider two measures of performance:</p>
<ul>
<li><p>Number of “Spot-on” recommendations - the number of users for whom a method is able to recommend the exact best item for them from those remaining.</p></li>
<li><p>Proportion of “Oracle” rating - the fraction of the best possible ratings achieved by a method (or the scores of a method divided by those of an “oracle” - a method that knew the ratings in advance and could offer everyone the best item for them).</p></li>
</ul>
<p>We repeat the inference many times on sampled data so that we can get an idea of the distribution of these measures, and also vary the number of initial recommednations and the variance in the ratings, to see how performance is affected.</p>
<pre class="r"><code>recdata.melt &lt;- melt(recdata,id.vars=c(&quot;NumUsers&quot;,&quot;NumItems&quot;,&quot;NumInitial&quot;,&quot;ID&quot;),measure.vars=c(&quot;RMSEMF&quot;,&#39;NumCorrectMF&#39;,&#39;PropOracleMF&#39;,&quot;NumCorrectRand&quot;,                        &quot;PropOracleRand&quot;,&quot;NumCorrectPopular&quot;, &quot;PropOraclePopular&quot;))
recdata.melt$NumInitial &lt;- as.factor(recdata.melt$NumInitial)

ggplot(recdata.melt[recdata.melt$variable%in%c(&quot;NumCorrectMF&quot;,&quot;NumCorrectPopular&quot;,&quot;NumCorrectRand&quot;),]) +
      geom_boxplot(aes(x=NumInitial, y=value,fill=variable)) + labs(x=&quot;Number of initial ratings&quot;,y=&quot;Number of spot-on recommendations&quot;,title=&quot;Effect of number of initial ratings on number of spot-on recommendations&quot;,subtitle=&quot;100 users, 40 items, ratings variance of 1&quot;) + scale_fill_discrete(name = &quot;Method&quot;, labels = c(&quot;Matrix Factorisation&quot;, &quot;Random&quot;, &quot;Popularity&quot;))</code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>ggplot(recdata.melt[recdata.melt$variable%in%c(&quot;PropOracleMF&quot;,&quot;PropOraclePopular&quot;,&quot;PropOracleRand&quot;),]) +
      geom_boxplot(aes(x=NumInitial, y=value,fill=variable)) + labs(x=&quot;Number of initial ratings&quot;,y=&quot;Proportion of Oracle rating&quot;,title=&quot;Effect of number of initial ratings on proportion of oracle rating&quot;,subtitle=&quot;100 users, 40 items, ratings variance of 1&quot;) + scale_fill_discrete(name = &quot;Method&quot;, labels = c(&quot;Matrix Factorisation&quot;, &quot;Random&quot;, &quot;Popularity&quot;))</code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<pre class="r"><code>ggplot(recdata.melt[recdata.melt$variable%in%c(&quot;NumCorrectMF&quot;,&quot;NumCorrectPopular&quot;,&quot;NumCorrectRand&quot;),]) +
      geom_boxplot(aes(x=RatingVariance, y=value,fill=variable)) + labs(x=&quot;Ratings Variance&quot;,y=&quot;Number of spot-on recommendations&quot;,title=&quot;Effect of ratings variance on number of spot-on recommendations&quot;,subtitle=&quot;100 users, 40 items, 10 initial ratings&quot;) + scale_fill_discrete(name = &quot;Method&quot;, labels = c(&quot;Matrix Factorisation&quot;, &quot;Random&quot;, &quot;Popularity&quot;))</code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>ggplot(recdata.melt[recdata.melt$variable%in%c(&quot;PropOracleMF&quot;,&quot;PropOraclePopular&quot;,&quot;PropOracleRand&quot;),]) +
      geom_boxplot(aes(x=RatingVariance, y=value,fill=variable)) + labs(x=&quot;Ratings Variance&quot;,y=&quot;Proportion of Oracle rating&quot;,title=&quot;Effect of number of initial ratings on proportion of oracle rating&quot;,subtitle=&quot;100 users, 40 items, 10 initial ratings&quot;) + scale_fill_discrete(name = &quot;Method&quot;, labels = c(&quot;Matrix Factorisation&quot;, &quot;Random&quot;, &quot;Popularity&quot;))</code></pre>
<p><img src="MHRecSys_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
</div>
<div id="conclusions-caveats-next-steps" class="section level2">
<h2>4. Conclusions, Caveats, Next Steps</h2>
<p>From the graphs above, it is clear that (in this set-up) the matrix factorization approach has the potential to do quite substantially better than approaches such as randomisation and popularity based recommendations. Unsurprisingly we also see that more initial ratings helps the matrix factorization method, and the more variability there is in the ratings, the worse the method performs.</p>
<p>These results are dependent, however, on the population ratings having a particular structure. In reality, user preferences are likely to be much more complex, and not have as strong and predictable relationships with user covariates as simulated here. Further exploration in to real data would help to assertain whether the improvement over simpler approaches would persist.</p>
<p>We may also be interested in further evaluation metrics - the methods we have considered focus on the aggregate performance over many users, but we may be interested in the quality of recommendations for individuals, and prefer to consider metrics such as the number of times something very poor is recommended or the worst rating obtained. Furthermore, we may have side-information that can be exploited. If, for instance, one of the user or item covariates was revealed to us, we ought to be able to make better inference and predictions.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
